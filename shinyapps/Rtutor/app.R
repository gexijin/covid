library(openai)
library(tidyverse)
library(shiny)
library(tippy)
library(gridExtra)

###################################################
# Global variables
###################################################

uploaded_data <- "Upload" 
min_query_length <- 10  # minimum # of characters
max_query_length <- 500 # max # of characters
language_model <- "text-davinci-003"

pdf(NULL) # this prevents error Cannot open file 'Rplots.pdf'

#' Move an element to the front of a vector
#'
#' The response from GPT3 sometimes contains strings that are not R commands.
#'
#' @param v is the vector
#' @param e is the element
#'
#' @return Returns a reordered vector
move_front <- function(v, e){
  ix <- which(v == e)

  # if found, move to the beginning.
  if(length(ix) != 0) {
    v <- v[-ix]
    v <- c(e, v)
  }
  return(v)
}


#' Prepare User input.
#'
#' The response from GPT3 sometimes contains strings that are not R commands.
#'
#' @param txt A string that stores the user input.
#' @param selected_data Name of the dataset.
#'
#' @return Returns a cleaned up version, so that it could be sent to GPT.
prep_input <- function(txt, selected_data){
  # if too short, do not send. 
  if(nchar(txt) < min_query_length || nchar(txt) > max_query_length) {
    return(NULL)
  }

  if(!is.null(selected_data)) {
    if(selected_data == uploaded_data) {
      selected_data <- "df"
    }
    txt <- paste("Use the", selected_data, "data frame. ", txt)
  }
  txt <- paste("Generate R code, not R Markdown. ", txt)

  # If the last character is not a stop, add it. 
  # Otherwise, GPT3 will add a sentence.

  # The following 5 lines were generated by ChatGPT!!!!!
  # Check if the last character is not a period
  if(substr(txt, nchar(txt), nchar(txt)) != ".") {
    # If the last character is not a period, add a period to the end of the string
    txt <- paste(txt, ".", sep = "")
  }

  return(txt)
}


#' Clean up R commands generated by GTP
#'
#' The response from GTP3 sometimes contains strings that are not R commands.
#'
#' @param cmd A string that stores the completion from GTP3.
#' @param selected_data, name of the selected dataset. 
#' @return Returns a cleaned up version, so that it could be executed as R command.
clean_cmd <- function(cmd, selected_data){
  # simple way to check
  if(grepl("That model is currently overloaded with other requests.|Error:", cmd)) {
    return(NULL)
  }
  # Use cat to converts \n to newline
  # use capture.output to get the string
  cmd <- capture.output(
    cat(cmd)
  )

  #cmd is a vector. Each element is a line.

  # sometimes it returns RMarkdown code.
  cmd <- gsub("```", "", cmd)

  # remove empty lines
  cmd <- cmd[cmd != ""]

  # replace install.packages by "#install.packages"
  cmd <- gsub("install.packages", "#install.packages", cmd)

  # if data is uploaded, add a line to get the data.
  if(selected_data == uploaded_data) {
    cmd <- c("df <- user_data()", cmd)
  }

  return(cmd)

}


###################################################################
# Prepare data
###################################################################
demos <- c(
  'Example requests:' = 'Example requests',

  'Boxplot ggplot2' = "Use ggplot2 to create a boxplot of hwy vs. class. Color by class.",
  'Boxplot in Base R' = "Create a boxplot of cty vs. class.",
  Scatter = "Use ggplot2. Plot hwy vs. cty, colored by class. Change shape by drv.",
  ANOVA = "Conduct ANOVA of hwy by class.",
  Boxplot2 = "Use ggplot2 to create a boxplot of hwy vs. class.  Color by class.
Add jitter.
Remove x label.",
  ANOVA2 = "Conduct ANOVA of log-transformed hwy by class and drv.",
  Correlation = "Create a correlation map of all the columns that contain numbers.",
  Barplot = "Calculate average cty by year and class.
Then use ggplot2 to create a barplot of average mpg by class,
colored by year. The years should be side by side.",
  Analysis = "Calculate the correlation of cty vs hwy.
Repeat that after log transformation.
Collect these results and show them.",
Analysis2 = "Only keep cars with hwy bigger than 15, but less than 40.
Add 0.5 to cty.
Perform log transformation on cty.
Raise hwy to the second power.
Calculate correlation coefficient of transformed hwy and cty.",
Analysis_complex = "hwy and cty represent miles per gallon (MPG) on the highway and in the city, respectively.
Only keep cars more efficient than 15 MPG, but less than 40, on the highway.
Add 0.5 to city MPG for correction.
Perform log transformation on city MPG.
Raise highway MPG to the second power.
Calculate correlation coefficient of  the two transformed variables.",
Neural_net = "Build a neural network model to predict 
hwy based on displ, cyl, and class.  
Use the nnet package. Plot the residules."
)

# prepare a list of available data sets.
datasets <- data()$results[, 3] # name of datasets
datasets <- gsub(" .*", "", datasets)
datasets <- move_front(datasets, "state.x77")
datasets <- move_front(datasets, "iris")
datasets <- move_front(datasets, "mtcars")
datasets <- move_front(datasets, "diamonds")
datasets <- move_front(datasets, "mpg")

# if dataset is not data frame or matrix, remove.
ix <- sapply(
  datasets, 
  function(x) {
    eval(
      parse(
        text = paste(
          "is.data.frame(",
          x,
          ") | is.matrix(",
           x, 
           ")"
        )
      )
    )
  }
)

datasets <- datasets[which(ix)]

# append a dummy value, used when user upload their data.
datasets <- c(datasets, uploaded_data)


###################################################################
# UI
###################################################################

ui <- fluidPage(
  titlePanel("RTutor - Do statistics in English"),
  # Sidebar with a slider input for number of bins
  sidebarLayout(
    sidebarPanel(
        # Application title

      p(HTML("<div align=\"right\"> <A HREF=\"javascript:history.go(0)\">Reset</A></div>")),
      fluidRow(
        column(
          width = 4,
          uiOutput("demo_data_ui")
        ),
        column(
          width = 8,
          uiOutput("data_upload_ui")
        )
      ),
      fluidRow(
        column(
          width = 8,
          uiOutput("prompt_ui")
        )
      ),

      tags$style(type = "text/css", "textarea {width:100%}"),
      tags$textarea(
        id = "input_text",
        placeholder = NULL,
        rows = 8, ""
      ),
      actionButton("submit_button", strong("Submit")),
      tags$head(tags$style(
        "#submit_button{font-size: 16px;color: red}"
      )),
      tippy::tippy_this(
        "submit_button",
        "ChatGPT can return different results for the same request.",
        theme = "light-border"
      ),
      br(),br(),
      downloadButton(
        outputId = "report",
        label = "Report"
      ),
      br(), br(),
      verbatimTextOutput("usage")
      ,verbatimTextOutput("result_class")
    ),

    # Show a plot of the generated distribution
    mainPanel(

      tabsetPanel(
        type = "tabs",
        tabPanel("Main",
          h4("AI generated R code:"),
          verbatimTextOutput("openAI"),
          br(), br(),
          h4("Results:"),
          uiOutput("results_ui"),
          br(), br(),
          tableOutput("data_table")
        ),

        tabPanel("Debug",
          verbatimTextOutput("prompt_ChatGPT"),
          verbatimTextOutput("R_cmd")
        ),

        tabPanel("About",
          p("Upload a data file and just analyze it in plain English. 
          Or used it to learn R and quickly lookup common commands."),
          h3("NO WARRANTY!"),
          h5(" Please use the auto-generated code as a starting point. Verify and validate the code and results."),
          h5("Supported formats include CSV, TSV/tab-delimited text files, and Excel."),
          h5("Powered by OpenAI's",
            a(
              "ChatGPT",
              href = "https://openai.com/blog/chatgpt/",
              target = "_blank"
            ), 
            ", using the ",
            language_model,
            "language model."
          ),
          p(" Personal hobby project by",
            a(
              "Xijin Ge.",
               href = "https://twitter.com/StevenXGe",
               target = "_blank"
            ),
            " For feedback, please email",
            a(
              "gexijin@gmail.com.",
              href = "mailto:gexijin@gmail.com?Subject=RTutor"
            )
          ),

          uiOutput("session_info")
        )
      )
    )
  )
  ,tags$head(includeScript("ga.js")) # tracking usage with Google analytics
)


###################################################################
# Server
###################################################################

server <- function(input, output, session) {

  # load demo data when clicked
  observe({
    req(input$demo_prompt)
    req(input$select_data)
    if(input$select_data == "mpg" && input$demo_prompt != demos[1]) {
      updateTextInput(
        session,
        "input_text",
        value = input$demo_prompt
      )
    } else { # if not mpg data, reset
      updateTextInput(
        session,
        "input_text",
        value = "",
        placeholder =
"Clearly state the desired statistical analysis in plain English. See examples above.

To see alternative solutions, try again with the same request.

The generated code only works correctly some of the times."
      )
    }
  })

  observeEvent(input$user_file, {
    updateSelectInput(
      session,
      "select_data",
      selected = uploaded_data
    )
  }, ignoreInit = TRUE, once = TRUE)

  observe({
    if (input$submit_button > 0) {
      updateTextInput(session, "submit_button", label = "Re-submit")
    }
  })

  user_data <- reactive({
    req(input$user_file)
    in_file <- input$user_file
    in_file <- in_file$datapath
    req(!is.null(in_file))

    isolate({
      # Excel file ---------------
      if(grepl("xls$|xlsx$", in_file, ignore.case = TRUE)) {
        df <- readxl::read_excel(in_file)
        df <- as.data.frame(df)
      } else {
        #CSV --------------------
        df <- read.csv(in_file)
        # Tab-delimented file ----------
        if (ncol(df) == 2) {
          df <- read.table(
            in_file,
            sep = "\t",
            header = TRUE
          )
        }
      }
      return(df)
    })
  })

  output$data_upload_ui <- renderUI({

    # Hide this input box after the first run.
    req(input$submit_button == 0)

    fileInput(
      inputId = "user_file",
      label = "Upload a file",
      accept = c(
        "text/csv",
        "text/comma-separated-values",
        "text/tab-separated-values",
        "text/plain",
        ".csv",
        ".tsv",
        ".txt",
        ".xls",
        ".xlsx"
      )
    )
  })

  output$demo_data_ui <- renderUI({

    # Hide this input box after the first run.
    req(input$submit_button == 0)

    selectInput(
      inputId = "select_data",
      label = "Dataset",
      choices = datasets,
      selected = "mpg",
      multiple = FALSE,
      selectize = FALSE
    )

  })

  output$prompt_ui <- renderUI({

    req(input$select_data)

    # hide after data is uploaded
    req(is.null(input$user_file))

    if(input$select_data == "mpg") {
      selectInput(
        inputId = "demo_prompt",
        choices = demos,
        label = NULL
      )
    } else {
      return(NULL)
    }
  })

  openAI_prompt <- reactive({
    req(input$submit_button)
    req(input$select_data)
    prep_input(input$input_text, input$select_data)
  })

  openAI_response <- reactive({

    req(input$submit_button)
    req(input$select_data)

    isolate({  # so that it will not responde to text, until submitted
      req(input$input_text)
      prepared_request <- openAI_prompt()
      req(prepared_request)

      withProgress(message = "Thinking ... (About 1 min)", value = 0, {
        incProgress(0.7)

        start_time <- Sys.time()
        # Send to openAI
        response <- create_completion(
          engine_id = language_model,
          prompt = prepared_request,
          openai_api_key = Sys.getenv("OPEN_API_KEY"),
          max_tokens = 500
        )
        api_time <- difftime(
          Sys.time(),
          start_time,
          units = "secs"
        )[[1]]

        #issue: check status

        cmd <- clean_cmd(response$choices[1, 1], input$select_data)

        return(
          list(
            cmd = cmd,
            response = response,
            time = round(api_time, 0)
          )
        )
      })
    })
  })

  output$openAI <- renderText({
    req(openAI_response()$cmd)
    res <- openAI_response()$response$choices[1, 1]
    # Replace multiple newlines with just one.
    res <- gsub("\n+", "\n", res)
    # Replace emplty lines,  [ ]{0, }--> zero or more space
    res <- gsub("^[ ]{0, }\n", "", res)
    res <- gsub("```", "", res)

  })

  output$usage <- renderText({
    req(openAI_response()$cmd)
    usage <- openAI_response()$response$usage

    paste0(
      "Tokens used: Input=",
      usage$prompt_tokens,
      ", Output=",
      usage$completion_tokens,
      ". \nCost=$", 
      sprintf("%f", usage$completion_tokens * 2e-5),
      "\nAPI time: ", 
      openAI_response()$time,
      " seconds."
    )

  })

  output$prompt_ChatGPT <- renderText({
    req(input$input_text)
    req(input$select_data)
    req(openAI_prompt())
    openAI_prompt()
  })
  output$R_cmd <- renderText({
    req(openAI_response()$cmd)
    openAI_response()$cmd
  })

  # stores the results after running the generated code.
  run_result <- reactive({
    req(openAI_response()$cmd)

    tryCatch(
      eval(parse(text = openAI_response()$cmd)),
      error = function(e) {
        #print(paste("Error caught:", e$message))
        return(
          list(
            value = -1,
            message = capture.output(print(e$message)),
            error_status = TRUE
          )
        )
      }
    )
  })

  output$result_plot <- renderPlot({
    req(openAI_response()$cmd)
    req(run_result())

    # if error, dummy plot with message
    if(code_error()) {
      grid::grid.newpage()
          grid::grid.text(
            paste(
              "Error: ",
              run_result()$message,
              "\nPlease try again by click Re-submit."
            ),
            x = 0.5,
            y = 0.85,
            gp = grid::gpar(
              col = "red",
              fontsize = 15
            )
          )
    } else {
      run_result() # show plot
    }
  })

  output$result_text <- renderText({
    req(openAI_response()$cmd)
    req(run_result())

    # if error, the returned list has two elements.
    if (code_error()) {
      paste(
        "Error: ",
        run_result()$message,
        "\n\nPlease try again by click Re-submit."
      )
    } else {
      res <- capture.output(run_result())
      return(paste(res, collapse = "\n"))
    }
  })

  # Error when run the generated code?
  code_error <- reactive({
    req(!is.null(run_result()))
    req(input$submit_button)
    req(openAI_response()$cmd)

    error_status <- FALSE

    # if error returns true, otherwise 
    #  that slot does not exist, returning false.
    # or be NULL
    error_status <- tryCatch(
      !is.null(run_result()$error_status),
      error = function(e) {
        return(TRUE)
      }
    )
    return(error_status)
  })

  output$result_class <- renderText({
    req(openAI_response()$cmd)
    req(run_result())

    paste(
      "Class:",
      paste(class(run_result()), collapse = " : "),
      "\nError:",
      paste(code_error(), collapse = " : ")
    )
  })

  output$results_ui <- renderUI({
    req(openAI_response()$cmd)

    # if the prompt include the "plot", generate a plot.
    # otherwise run statistical analysis.
    if(sum(grepl("plot|Plot|PLOT", openAI_response()$cmd)) > 0) {
      plotOutput("result_plot")
    } else {
      verbatimTextOutput("result_text")
    }
  })

  output$data_table <- renderTable({
    req(input$select_data)
    if(input$select_data == uploaded_data) {
      eval(parse(text = paste0("user_data()[1:20, ]")))
    } else {
      eval(parse(text = paste0(input$select_data, "[1:20, ]")))
    }
  },
  striped = TRUE,
  bordered = TRUE,
  hover = TRUE
  )



  output$session_info <- renderUI({
    i <- c("<br><h4>R session info: </h4>")
    i <- c(i, capture.output(sessionInfo()))
    HTML(paste(i, collapse = "<br/>"))
  })

  # Markdown report
  output$report <- downloadHandler(
    # For PDF output, change this to "report.pdf"
    filename = "RTutor_report.html",
    content = function(file) {
      withProgress(message = "Generating Report ...", {
        incProgress(0.2)

        tempReport <- file.path(tempdir(), "report.Rmd")
        # tempReport
        tempReport <- gsub("\\", "/", tempReport, fixed = TRUE)

        req(openAI_response()$cmd)
        req(openAI_prompt())

        #RMarkdown file's Header
        Rmd_script <- paste0(
          "---\n",
          "title: \"Report\"\n",
          "author: \"RTutor, Powered by ChatGPT\"\n",
          "date: \"",
          date(), "\"\n",
          "output: html_document\n",
          "params:\n",
          "  df:\n",
          "printcode:\n",
          "  label: \"Display Code\"\n",
          "  value: TRUE\n",
          "  input: checkbox\n",
          "---\n"
        )

        # if uploaded, remove the line: df <- user_data()
        cmd <- openAI_response()$cmd
        if(input$select_data == uploaded_data) {
          cmd <- cmd[-1]
        }

        Rmd_script <- paste0(
          Rmd_script,
          # Get the data from the params list-----------
          "\n\n```{R, echo = FALSE}\n",
          "df <- params$df\n",
          "\n```\n",
          "\n\n### ",
          paste(
            openAI_prompt(),
            collapse = "\n"
          )
        )

        # R Markdown code chuck----------------------
        #if error when running the code, do not run
        if(code_error()) {
          Rmd_script <- paste(
            Rmd_script,
            "\n```{R, eval = FALSE}\n"
          )
        } else {
          Rmd_script <- paste(
            Rmd_script,
            "\n```{R}\n"
          )
        }

        # Add R code
        Rmd_script <- paste(
          Rmd_script,
          paste(
            cmd,
            collapse = "\n"
          ),
          "\n```\n"
        )

        write(
          Rmd_script,
          file = tempReport,
          append = FALSE
        )

        # Set up parameters to pass to Rmd document
        params <- list(
          df = iris #dummy
        )

        # if uploaded, use that data
        req(input$select_data)
        if(input$select_data == uploaded_data) {
          params <- list(
            df = user_data()
          )
        }

        req(params)
        # Knit the document, passing in the `params` list, and eval it in a
        # child of the global environment (this isolates the code in the document
        # from the code in this app).
        rmarkdown::render(
          input = tempReport, # markdown_location,
          output_file = file,
          params = params,
          envir = new.env(parent = globalenv())
        )
      })
    }
  )
}

shinyApp(ui = ui, server = server)

# Run the application
# shiny::runApp("app.R")
